{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion MNIST Classification using Neural Networks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll train a neural network to classify images of clothing items from the [Fashion MNIST dataset](https://github.com/zalandoresearch/fashion-mnist). The dataset consists of 70,000 grayscale images in 10 classes: T-shirt/top, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, and Ankle boot. Each image is 28x28 pixels, and the classes are mutually exclusive.\n",
    "\n",
    "We'll use the [Keras](https://keras.io/) deep learning framework to build and train our neural network. Keras provides a high-level API that makes it easy to define and train neural networks, even for beginners."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries\n",
    "\n",
    "Let's start by importing the necessary libraries for our project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import *\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras import models\n",
    "from keras import layers\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use NumPy for numerical operations, Matplotlib for visualization, and Keras for building and training the neural network."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "Next, we'll load the Fashion MNIST dataset and split it into training and testing sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the fashion MNIST dataset and splitting it into training and testing sets\n",
    "(train_images, train_labels), (test_images,\n",
    "                               test_labels) = fashion_mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in the training set: 60000\n",
      "Number of labels in the training set: 60000\n",
      "Number of samples in the test set: 10000\n",
      "Number of labels in the test set: 10000\n"
     ]
    }
   ],
   "source": [
    "# Printing the number of samples in the training and testing sets\n",
    "print(\"Number of samples in the training set:\", len(train_images))\n",
    "print(\"Number of labels in the training set:\", len(train_labels))\n",
    "print(\"Number of samples in the test set:\", len(test_images))\n",
    "print(\"Number of labels in the test set:\", len(test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the testing images array: (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Printing the shape of the testing images array\n",
    "print(\"Shape of the testing images array:\", test_images.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the testing images array: (60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Printing the shape of the train images array\n",
    "print(\"Shape of the testing images array:\", train_images.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We print the number of samples and labels in the training and testing sets to verify that the dataset was loaded correctly."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Data\n",
    "Let's take a look at an example image from the testing set and its corresponding class label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Label: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Displaying an example image from the testing set and its class label\n",
    "digit = test_images[120]\n",
    "print(\"Class Label:\", test_labels[120])\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code displays the 120th image from the testing set (a sandal) and its class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique class labels in the training set: array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)\n",
      "Unique class labels in the training set: array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)\n",
      "Unique class labels in the test set: array([9, 2, 1, ..., 8, 1, 5], dtype=uint8)\n",
      "Unique class labels in the test set: array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)\n"
     ]
    }
   ],
   "source": [
    "# Printing the unique class labels in the training and testing sets\n",
    "print(\"Unique class labels in the training set:\", train_labels)\n",
    "print(\"Unique class labels in the training set:\", np.unique(train_labels))\n",
    "print(\"Unique class labels in the test set:\", test_labels)\n",
    "print(\"Unique class labels in the test set:\", np.unique(test_labels))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Neural Network\n",
    "We'll use a simple neural network with two layers: a fully connected hidden layer with 512 units and ReLU activation, and a fully connected output layer with 10 units and softmax activation. We'll define the neural network using Keras' Sequential API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the neural network architecture\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(28*28, )))\n",
    "network.add(layers.Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the Model\n",
    "Now that we've defined the neural network architecture, we need to compile the model. We'll use the rmsprop optimizer and categorical_crossentropy loss function, and track accuracy as a metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model by specifying the optimizer, loss function, and evaluation metrics\n",
    "network.compile(optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.ndim\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the Data\n",
    "Before training the neural network, we need to preprocess the data. First, we'll reshape the images arrays to have a single dimension of length 784 (28x28). Then, we'll normalize the pixel values to be between 0 and 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping and normalizing the training and testing images arrays\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255  # Normalization\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255  # Normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also cast the pixel values to float32 to avoid numerical issues during training.\n",
    "\n",
    "Next, we'll convert the class labels to one-hot encoded vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the class labels to one-hot encoded vectors\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This allows us to use categorical crossentropy as the loss function for training the neural network."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "We're now ready to train the neural network. We'll use the fit() method to train the model on the training set for 5 epochs with a batch size of 128:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.5579 - accuracy: 0.8027\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.3844 - accuracy: 0.8588\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.3397 - accuracy: 0.8761\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.3128 - accuracy: 0.8833\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.2939 - accuracy: 0.8904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c92c8f2610>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the neural network on the training set\n",
    "network.fit(train_images, train_labels, epochs=5, batch_size=128)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model\n",
    "Finally, we'll evaluate the performance of the model on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4169 - accuracy: 0.8432\n",
      "Test accuracy: 0.8432000279426575\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the performance of the trained model on the test set\n",
    "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We print the test accuracy as the final metric."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code loads the fashion MNIST dataset and trains a neural network to classify images of clothing items into 10 different classes. The neural network has two layers: a fully connected hidden layer with 512 units and ReLU activation, and a fully connected output layer with 10 units and softmax activation. The model is compiled with the RMSprop optimizer, categorical crossentropy loss function, and accuracy as the evaluation metric. The training and testing images arrays are reshaped to have a single dimension of length 784 and are normalized to have pixel values between 0 and 1. The class labels are converted to one-hot encoded vectors before training the model. The model is trained for 5 epochs with a batch size of 128, and its performance is evaluated on the test set. Finally, the test accuracy is printed."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! We've built a neural network that can classify images of clothing items with high accuracy. With some tweaking of the neural network architecture and training parameters, we can likely improve the performance even further."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
